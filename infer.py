import os
import shutil
import torch
from torchvision import transforms
from PIL import Image
from models.backbone import get_model

# ================= é…ç½®åŒº =================
# 1. æ¨¡å‹è·¯å¾„
CHECKPOINT_PATH = "./outputs/checkpoints/best_model.pth"

# 2. å¾…å¤„ç†çš„ä¹±åºå›¾ç‰‡æ–‡ä»¶å¤¹ (è¾“å…¥)
INPUT_DIR = "./data/raw/new_batch_images"

# 3. åˆ†ç±»ç»“æœå­˜æ”¾æ–‡ä»¶å¤¹ (è¾“å‡º)
OUTPUT_DIR = "./data/sorted_result"

# 4. ç±»åˆ«åˆ—è¡¨ (å¿…é¡»ä¸è®­ç»ƒæ—¶çš„é¡ºåºå®Œå…¨ä¸€è‡´ï¼)
# ä½ å¯ä»¥æŸ¥çœ‹ data/train ä¸‹çš„æ–‡ä»¶å¤¹é¡ºåºï¼Œæˆ–è€…è®­ç»ƒæ—¶çš„ log
CLASS_NAMES = [
    "01_overall", "02_carbon_slide", "03_fixing_bolts", "04_joint_bearing",
    "05_guide_rod", "06_lower_shunt", "07_head_shunt", "08_mid_shunt",
    "09_pan_head", "10_bracket", "11_camera"
]


# =========================================

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹... (ä½¿ç”¨è®¾å¤‡: {device})")

    # 1. åŠ è½½æ¨¡å‹ç»“æ„
    model = get_model(num_classes=len(CLASS_NAMES), pretrained=False, freeze_backbone=False)

    # 2. åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    # map_locationç¡®ä¿åœ¨æ²¡æœ‰GPUçš„ç”µè„‘ä¸Šä¹Ÿèƒ½ç”¨CPUè¿è¡Œ
    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
    model.load_state_dict(checkpoint)
    model.to(device)
    model.eval()  # åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼

    # 3. å®šä¹‰é¢„å¤„ç† (åªåšç¼©æ”¾å’Œå½’ä¸€åŒ–ï¼Œä¸åšéšæœºå¢å¼º)
    infer_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    print(f"ğŸ“‚ æ‰«ææ–‡ä»¶å¤¹: {INPUT_DIR}")

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    count = 0
    # éå†æ‰€æœ‰å›¾ç‰‡
    for root, dirs, files in os.walk(INPUT_DIR):
        for file in files:
            if not file.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp')):
                continue

            img_path = os.path.join(root, file)

            try:
                # è¯»å–å¹¶å¤„ç†å›¾ç‰‡
                image = Image.open(img_path).convert('RGB')
                input_tensor = infer_transform(image).unsqueeze(0).to(device)  # å¢åŠ  batch ç»´åº¦

                # æ¨ç†
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probs = torch.nn.functional.softmax(outputs, dim=1)
                    confidence, preds = torch.max(probs, 1)

                class_idx = preds.item()
                class_name = CLASS_NAMES[class_idx]
                conf_score = confidence.item()

                # åªæœ‰ç½®ä¿¡åº¦å¤§äº 0.6 æ‰åˆ†ç±»ï¼Œå¦åˆ™å¯ä»¥ä¸¢åˆ° "unknown" æ–‡ä»¶å¤¹
                if conf_score > 0.6:
                    target_folder = os.path.join(OUTPUT_DIR, class_name)
                    os.makedirs(target_folder, exist_ok=True)

                    # ç§»åŠ¨æ–‡ä»¶ (å¦‚æœæƒ³ä¿ç•™åŸå›¾ç”¨ shutil.copy)
                    shutil.move(img_path, os.path.join(target_folder, file))
                    print(f"âœ… [{class_name}] (conf: {conf_score:.2f}) -> {file}")
                    count += 1
                else:
                    print(f"âš ï¸ [è·³è¿‡] ç½®ä¿¡åº¦è¿‡ä½ ({conf_score:.2f}) -> {file}")

            except Exception as e:
                print(f"âŒ å¤„ç†å‡ºé”™ {file}: {e}")

    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼å…±åˆ†ç±»å½’æ¡£ {count} å¼ å›¾ç‰‡ã€‚")
    print(f"ç»“æœä¿å­˜åœ¨: {os.path.abspath(OUTPUT_DIR)}")


if __name__ == "__main__":
    main()