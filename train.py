import os
import copy
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import argparse
import json

# å¼•å…¥æˆ‘ä»¬åœ¨ models/backbone.py å®šä¹‰çš„æ¨¡å‹
from models.backbone import get_model


# ================= é…ç½®åŒº =================
#  (é…ç½®è·¯å¾„ç°åœ¨é€šè¿‡å‘½ä»¤è¡Œè¯»å–ï¼Œè¿™é‡Œç•™ç©ºå³å¯)
# =========================================

# ã€æ–°å¢ã€‘è¡¥å›è¿™ä¸ªè¯»å– yaml æ–‡ä»¶çš„è¾…åŠ©å‡½æ•°
def load_config(path):
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def main():
    # --- ä¿®æ”¹å¼€å§‹: ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¯»å–é…ç½® ---
    parser = argparse.ArgumentParser(description='Train Pantograph Classifier')
    # é»˜è®¤è·¯å¾„è®¾ä¸º type_B.yamlï¼Œæ–¹ä¾¿ä½ ç›´æ¥ç‚¹è¿è¡Œ
    parser.add_argument('--config', type=str, default='./configs/type_C.yaml', help='Path to config file')
    args = parser.parse_args()

    CONFIG_PATH = args.config

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢æŠ¥é”™æ‡µé€¼
    if not os.path.exists(CONFIG_PATH):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_PATH}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")

    cfg = load_config(CONFIG_PATH)  # ç°åœ¨è¿™é‡Œå¯ä»¥æ­£å¸¸å·¥ä½œäº†
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ å¯åŠ¨è®­ç»ƒï¼Œè¯»å–é…ç½®: {CONFIG_PATH}")
    print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {cfg['data']['root_dir']}")
    print(f"ğŸ’¾ æ¨¡å‹å°†ä¿å­˜è‡³: ./outputs/{cfg['project_name']}")

    # 2. æ•°æ®é¢„å¤„ç†ä¸å¢å¼º
    # è®­ç»ƒé›†ï¼šå¢åŠ éšæœºæ‰°åŠ¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    data_transforms = {
        'train': transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop(cfg['data']['input_size']),
            transforms.RandomHorizontalFlip(),
            transforms.ColorJitter(brightness=0.1, contrast=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Resize((cfg['data']['input_size'], cfg['data']['input_size'])),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    # 3. åŠ è½½æ•°æ®é›† (ä½¿ç”¨ ImageFolder è‡ªåŠ¨è¯»å–æ–‡ä»¶å¤¹åˆ†ç±»)
    data_dir = cfg['data']['root_dir']

    # å¢åŠ è·¯å¾„æ£€æŸ¥
    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®ç›®å½•: {data_dir}ï¼Œè¯·ç¡®è®¤ type_B æ•°æ®æ˜¯å¦å·²ç”Ÿæˆï¼")

    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])
                      for x in ['train', 'val']}

    dataloaders = {x: DataLoader(image_datasets[x],
                                 batch_size=cfg['data']['batch_size'],
                                 shuffle=(x == 'train'),  # è®­ç»ƒé›†æ‰“ä¹±ï¼ŒéªŒè¯é›†ä¸éœ€è¦
                                 num_workers=cfg['data']['num_workers'])
                   for x in ['train', 'val']}

    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
    class_names = image_datasets['train'].classes

    print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: è®­ç»ƒé›† {dataset_sizes['train']} å¼  | éªŒè¯é›† {dataset_sizes['val']} å¼ ")
    print(f"ğŸ·ï¸ æ£€æµ‹åˆ° {len(class_names)} ä¸ªç±»åˆ«: {class_names}")

    # 4. åˆå§‹åŒ–æ¨¡å‹
    # æ³¨æ„ï¼šè¿™é‡Œè¯»å–çš„æ˜¯ len(class_names)ï¼Œæ‰€ä»¥ yaml é‡Œçš„ num_classes å†™é”™äº†ä¹Ÿä¸å½±å“ï¼Œä»¥æ–‡ä»¶å¤¹å®é™…æ•°é‡ä¸ºå‡†
    model = get_model(num_classes=len(class_names), pretrained=cfg['model']['pretrained'])
    model = model.to(device)

    # 5. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),
                           lr=cfg['train']['learning_rate'])

    # 6. è®­ç»ƒå¾ªç¯
    num_epochs = cfg['train']['epochs']
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # ä¿å­˜è·¯å¾„æ ¹æ® project_name åŠ¨æ€ç”Ÿæˆ
    save_dir = os.path.join("./outputs", cfg['project_name'])
    os.makedirs(save_dir, exist_ok=True)

    # ä¿å­˜ json æ ‡ç­¾
    with open(os.path.join(save_dir, 'classes.json'), 'w', encoding='utf-8') as f:
        json.dump(class_names, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ ç±»åˆ«æ˜ å°„è¡¨å·²ä¿å­˜è‡³: {os.path.join(save_dir, 'classes.json')}")

    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch + 1}/{num_epochs}')
        print('-' * 10)

        # æ¯ä¸ª epoch éƒ½æœ‰è®­ç»ƒå’ŒéªŒè¯é˜¶æ®µ
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            # è¿›åº¦æ¡
            pbar = tqdm(dataloaders[phase], desc=f"{phase} Phase", unit="batch")

            for inputs, labels in pbar:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                # å‰å‘ä¼ æ’­
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # åå‘ä¼ æ’­ (åªåœ¨è®­ç»ƒé˜¶æ®µ)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # ç»Ÿè®¡
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºçš„å½“å‰ Loss
                pbar.set_postfix({'loss': f"{loss.item():.4f}"})

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # æ·±åº¦å¤åˆ¶æœ€ä¼˜æ¨¡å‹ (åŸºäºéªŒè¯é›†å‡†ç¡®ç‡)
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
                torch.save(model.state_dict(), os.path.join(save_dir, "best_model.pth"))
                print(f"âœ¨ æ–°çš„æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜ (Acc: {best_acc:.4f})")

    print(f'\nğŸ è®­ç»ƒå®Œæˆã€‚æœ€ä¼˜éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:.4f}')
    print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹ä½äº: {os.path.abspath(save_dir)}")


if __name__ == '__main__':
    main()